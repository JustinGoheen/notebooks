{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMBxzWHqEEHWFP5wqRIo+Ca",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JustinGoheen/notebooks/blob/main/textlab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install PyTorch Lightning"
      ],
      "metadata": {
        "id": "ndPqghCTpNqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are running this locally and haven't already installed PyTorch Lightning, you can do so with:\n",
        "\n",
        "```sh\n",
        "pip install pytorch-lightning\n",
        "```"
      ],
      "metadata": {
        "id": "MqDR0rdO6uPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install \"pytorch-lightning>=2.0\" -q"
      ],
      "metadata": {
        "id": "ZXoooct1ogSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import PyTorch Lightning and TorchMetrics"
      ],
      "metadata": {
        "id": "JLTTPnTPpW5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import torchmetrics as tm"
      ],
      "metadata": {
        "id": "NsYVgWj1pX2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the Transformer and Dataset"
      ],
      "metadata": {
        "id": "2kvxW9bupcKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.demos.transformer import Transformer, WikiText2"
      ],
      "metadata": {
        "id": "OtalT4YFoZHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import PyTorch"
      ],
      "metadata": {
        "id": "Z25J5fPQpTFM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfRLeL8HoNlA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the Custom LightningDataModule"
      ],
      "metadata": {
        "id": "UNnuqvMSyBbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "from pytorch_lightning.utilities.types import EVAL_DATALOADERS, TRAIN_DATALOADERS\n",
        "\n",
        "\n",
        "class WikiText2DataModule(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_workers: int = 2,\n",
        "        data_dir: Path = Path(\"./tutorial_data\"),\n",
        "        block_size: int = 35,\n",
        "        download: bool = True,\n",
        "        train_size: float = 0.8,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.block_size = block_size\n",
        "        self.download = download\n",
        "        self.num_workers = num_workers\n",
        "        self.train_size = train_size\n",
        "\n",
        "    def prepare_data(self) -> None:\n",
        "        self.dataset = WikiText2(data_dir=self.data_dir, block_size=self.block_size, download=self.download)\n",
        "\n",
        "    def setup(self, stage: str) -> None:\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            train_size = int(len(self.dataset) * self.train_size)\n",
        "            test_size = len(self.dataset) - train_size\n",
        "            self.train_data, self.val_data = random_split(self.dataset, lengths=[train_size, test_size])\n",
        "        if stage == \"test\" or stage is None:\n",
        "            self.test_data = self.val_data\n",
        "\n",
        "    def train_dataloader(self) -> TRAIN_DATALOADERS:\n",
        "        return DataLoader(self.train_data, num_workers=self.num_workers)\n",
        "\n",
        "    def val_dataloader(self) -> EVAL_DATALOADERS:\n",
        "        return DataLoader(self.val_data, num_workers=self.num_workers)\n",
        "\n",
        "    def test_dataloader(self) -> EVAL_DATALOADERS:\n",
        "        return DataLoader(self.test_data, num_workers=self.num_workers)\n"
      ],
      "metadata": {
        "id": "xyW_Qf1QyFtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the LanguageModel class using LightningModule"
      ],
      "metadata": {
        "id": "GCY16qs8pjUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel(pl.LightningModule):\n",
        "    def __init__(self, vocab_size: int = 33278):\n",
        "        super().__init__()\n",
        "        self.model = Transformer(vocab_size=vocab_size)\n",
        "\n",
        "    def forward(self, inputs, target):\n",
        "        return self.model(inputs, target)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        inputs, target = batch\n",
        "        output = self(inputs, target)\n",
        "        loss = torch.nn.functional.nll_loss(output, target.view(-1))\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.SGD(self.model.parameters(), lr=0.1)\n",
        "\n",
        "    def prepare_data(self):\n",
        "        WikiText2(download=True)"
      ],
      "metadata": {
        "id": "GI4FKGX_pLP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Trainer"
      ],
      "metadata": {
        "id": "oFvZtDRCqgFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the Dataset"
      ],
      "metadata": {
        "id": "TJj2HjV-zxYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datamodule = WikiText2DataModule()"
      ],
      "metadata": {
        "id": "odlux34Bz1GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate a Model Object"
      ],
      "metadata": {
        "id": "Z7-oK9b2z1wC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel()"
      ],
      "metadata": {
        "id": "AaDiKVLtz6ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate a Trainer Object"
      ],
      "metadata": {
        "id": "Zms-v9UUz8EL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logsdir = \"./lightning_logs\""
      ],
      "metadata": {
        "id": "CSZAQCZqDKvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(\n",
        "    max_epochs=2,\n",
        "    logger=pl.loggers.CSVLogger(logsdir),\n",
        "    profiler=pl.profilers.SimpleProfiler(dirpath=logsdir)\n",
        ")"
      ],
      "metadata": {
        "id": "no4IhOhaqfCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "T_GNcVxBtBRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import perf_counter"
      ],
      "metadata": {
        "id": "E5CJdwOg9phs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = perf_counter()\n",
        "trainer.fit(model=model, datamodule=datamodule)\n",
        "t2 = perf_counter()"
      ],
      "metadata": {
        "id": "r8RxGwn3tA-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(t2 - t1)"
      ],
      "metadata": {
        "id": "xM4NrdWHCc5E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}